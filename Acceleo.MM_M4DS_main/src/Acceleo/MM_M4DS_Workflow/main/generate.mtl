[comment encoding = UTF-8 /]
[**
 * The documentation of the module generate.
 */]
[module generate('https://www.example.org/workflow', 'https://www.example.org/contract')]

[import Acceleo::MM_M4DS_contract::main::generate/]


[**
 * The documentation of the template generateElement.
 * @param aWorkflow
 */]

[template public generateWorkflow(aWorkflow : Workflow)]
[comment @main/]
[generateDataProcessing(aWorkflow)/]
[generateContractsDataProcessing(aWorkflow)/]
[generateTransformationsDataProcessing(aWorkflow)/]
[/template]


[template public generateDataProcessing(aWorkflow : Workflow)]
[file ('dataProcessing.py', false, 'UTF-8')]
import os
import pandas as pd
import functions.contract_invariants as contract_invariants
import functions.contract_pre_post as contract_pre_post
import functions.data_transformations as data_transformations
from helpers.enumerations import Belong, Operator, Operation, SpecialType, DataType, DerivedType, Closure
[comment generate the imports and the class/]
class DataProcessing:
	def generateDataProcessing(self):
		pre_post=contract_pre_post.ContractsPrePost()
		invariants=contract_invariants.Invariants()
		transformations=data_transformations.DataTransformations()
	[for (d : DataProcessing | aWorkflow.dataprocessing)]				[comment OPEN traverse all the DataProcessings/]
	[if (d.incoming = null and d.outgoing=null)]						[comment OPEN checks if the DataProcessing is isolated (no links)/]
#-----------------New DataProcessing-----------------
			[for (dc : DataDictionary | d.inputPort)]					[comment OPEN read all the input datasets and store them/]
		[dc.name/]=pd.read_csv('[dc.path/]')

			[/for]														[comment CLOSE read all the input datasets and store them/]
		[for (c : Contract | d.contract)]								[comment OPEN traverse all the contracts in the DataProcessing/]
		[if (c.contract.type=ContractType::PRECONDITION)]				[comment OPEN checks if the if the contract is a Precondition/]
		[generateCallContract(c.contract)/]
		[/if]															[comment CLOSE checks if the if the contract is a Precondition/]
		[/for]															[comment CLOSE traverse all the contracts in the DataProcessing/]
		[generateCallTransformation(d)/]
		[for (c : Contract | d.contract)]								[comment OPEN traverse all the contracts in the DataProcessing/]
		[if (c.contract.type=ContractType::POSTCONDITION)]				[comment OPEN checks if the if the contract is a Postcondition/]
		[generateCallContract(c.contract)/]
		[/if]															[comment CLOSE checks if the if the contract is a Postcondition/]
		[/for]															[comment CLOSE traverse all the contracts in the DataProcessing/]
		[for (c : Contract | d.contract)]								[comment OPEN traverse all the contracts in the DataProcessing/]
		[if (c.contract.type=ContractType::INVARIANT)]					[comment OPEN checks if the if the contract is a Invariant/]
		[generateCallContract(c.contract)/]
		[/if]															[comment CLOSE checks if the if the contract is a Invariant/]
		[/for]															[comment CLOSE traverse all the contracts in the DataProcessing/]
	[/if]																[comment CLOSE checks if the DataProcessing is isolated (no links)/]
	[/for]																[comment CLOSE traverse all the DataProcessings/]
	[for (d : DataProcessing | aWorkflow.dataprocessing)]				[comment OPEN traverse all the DataProcessings/]
	[if (d.incoming = null and d.outgoing<>null)]						[comment OPEN checks if the DataProcessing is the first (no input link, an output link)/]
[callRecursiveTemplate(d)/]
	[/if]																[comment CLOSE checks if the DataProcessing is the first (no input link, an output link)/]
	[/for]																[comment CLOSE traverse all the DataProcessings/]


dp=DataProcessing()
dp.generateDataProcessing()
[/file]
[/template]


[template public callRecursiveTemplate(d : DataProcessing)]
#-----------------New DataProcessing-----------------
[for (dc : DataDictionary | d.inputPort)]									[comment OPEN read all the input datasets and store them/]
		[dc.name/]=pd.read_csv('[dc.path/]')

[/for]																		[comment CLOSE read all the input datasets and store them/]
[for (c : Contract | d.contract)]											[comment OPEN traverse all the contracts in the DataProcessing/]
	[if (c.contract.type=ContractType::PRECONDITION)]						[comment OPEN checks if the if the contract is a Precondition/]
		[generateCallContract(c.contract)/]
	[/if]																	[comment CLOSE checks if the if the contract is a Precondition/]
[/for]																		[comment CLOSE traverse all the contracts in the DataProcessing/]
		[generateCallTransformation(d)/]
[for (c : Contract | d.contract)]											[comment OPEN traverse all the contracts in the DataProcessing/]
	[if (c.contract.type=ContractType::POSTCONDITION)]						[comment OPEN checks if the if the contract is a Postcondition/]
		[generateCallContract(c.contract)/]
	[/if]																	[comment CLOSE checks if the if the contract is a Postcondition/]
[/for]																		[comment CLOSE traverse all the contracts in the DataProcessing/]
[for (c : Contract | d.contract)]											[comment OPEN traverse all the contracts in the DataProcessing/]
	[if (c.contract.type=ContractType::INVARIANT)]							[comment OPEN checks if the if the contract is a Invariant/]
		[generateCallContract(c.contract)/]
	[/if]																	[comment CLOSE checks if the if the contract is a Invariant/]
[/for]
	[if (d.outgoing<>null)]													[comment OPEN checks if the DataProcessing has an outgoing link (it's not the last)/]
[let nextDp : DataProcessing = d.outgoing.target.oclAsType(DataProcessing)] [comment OPEN assigns the next DataProcessing to a variable/]
[callRecursiveTemplate(nextDp)/]			[comment Recursive call to this template to generate all the DataProcessings linked to the first/]
[/let]																		[comment OPEN assigns the next DataProcessing to a variable/]
	[/if]																	[comment CLOSE checks if the DataProcessing has an outgoing link (it's not the last)/]
[/template]

[comment]################################################################################################################################################################[/comment]

[template public generateContractsDataProcessing(aWorkflow : Workflow)]
[file ('contracts.py', false, 'UTF-8')]
import os
import pandas as pd
import functions.contract_invariants as contract_invariants
import functions.contract_pre_post as contract_pre_post
from helpers.enumerations import Belong, Operator, Operation, SpecialType, DataType, DerivedType, Closure
[comment generate the imports and the class/]
class DataProcessing:
	def generateDataProcessing(self):
		pre_post=contract_pre_post.ContractsPrePost()
		invariants=contract_invariants.Invariants()
	[for (d : DataProcessing | aWorkflow.dataprocessing)]				[comment OPEN traverse all the DataProcessings/]
	[if (d.incoming = null and d.outgoing=null)]						[comment OPEN checks if the DataProcessing is isolated (no links)/]
#-----------------New DataProcessing-----------------
			[for (dc : DataDictionary | d.inputPort)]					[comment OPEN read all the input datasets and store them/]
		[dc.name/]=pd.read_csv('[dc.path/]')

			[/for]														[comment CLOSE read all the input datasets and store them/]
			[for (dc : DataDictionary | d.outputPort)]					[comment OPEN read all the output datasets and store them/]
		if path.exists('[dc.path/]'):		#If the output DataDictionary exists, we store it
			[dc.name/]=pd.read_csv('[dc.path/]')

			[/for]														[comment CLOSE read all the output datasets and store them/]
		[for (c : Contract | d.contract)]								[comment OPEN traverse all the contracts in the DataProcessing/]
		[if (c.contract.type=ContractType::PRECONDITION)]				[comment OPEN checks if the if the contract is a Precondition/]
		[generateCallContract(c.contract)/]
		[/if]															[comment CLOSE checks if the if the contract is a Precondition/]
		[/for]															[comment CLOSE traverse all the contracts in the DataProcessing/]
		[for (c : Contract | d.contract)]								[comment OPEN traverse all the contracts in the DataProcessing/]
		[if (c.contract.type=ContractType::POSTCONDITION)]				[comment OPEN checks if the if the contract is a Postcondition/]
		[generateCallContract(c.contract)/]
		[/if]															[comment CLOSE checks if the if the contract is a Postcondition/]
		[/for]															[comment CLOSE traverse all the contracts in the DataProcessing/]
		[for (c : Contract | d.contract)]								[comment OPEN traverse all the contracts in the DataProcessing/]
		[if (c.contract.type=ContractType::INVARIANT)]					[comment OPEN checks if the if the contract is a Invariant/]
		[generateCallContract(c.contract)/]
		[/if]															[comment CLOSE checks if the if the contract is a Invariant/]
		[/for]															[comment CLOSE traverse all the contracts in the DataProcessing/]
	[/if]																[comment CLOSE checks if the DataProcessing is isolated (no links)/]
	[/for]																[comment CLOSE traverse all the DataProcessings/]
	[for (d : DataProcessing | aWorkflow.dataprocessing)]				[comment OPEN traverse all the DataProcessings/]
	[if (d.incoming = null and d.outgoing<>null)]						[comment OPEN checks if the DataProcessing is the first (no input link, an output link)/]
[callContractsRecursiveTemplate(d)/]
	[/if]																[comment CLOSE checks if the DataProcessing is the first (no input link, an output link)/]
	[/for]																[comment CLOSE traverse all the DataProcessings/]


dp=DataProcessing()
dp.generateDataProcessing()
[/file]
[/template]


[template public callContractsRecursiveTemplate(d : DataProcessing)]
#-----------------New DataProcessing-----------------
[for (dc : DataDictionary | d.inputPort)]									[comment OPEN read all the input datasets and store them/]
		[dc.name/]=pd.read_csv('[dc.path/]')

[/for]																		[comment CLOSE read all the input datasets and store them/]
[for (dc : DataDictionary | d.outputPort)]									[comment OPEN read all the output datasets and store them/]
		if path.exists('[dc.path/]'):		#If the output DataDictionary exists, we store it
			[dc.name/]=pd.read_csv('[dc.path/]')

[/for]																		[comment CLOSE read all the output datasets and store them/]
[for (c : Contract | d.contract)]											[comment OPEN traverse all the contracts in the DataProcessing/]
	[if (c.contract.type=ContractType::PRECONDITION)]						[comment OPEN checks if the if the contract is a Precondition/]
		[generateCallContract(c.contract)/]
	[/if]																	[comment CLOSE checks if the if the contract is a Precondition/]
[/for]																		[comment CLOSE traverse all the contracts in the DataProcessing/]
[for (c : Contract | d.contract)]											[comment OPEN traverse all the contracts in the DataProcessing/]
	[if (c.contract.type=ContractType::POSTCONDITION)]						[comment OPEN checks if the if the contract is a Postcondition/]
		[generateCallContract(c.contract)/]
	[/if]																	[comment CLOSE checks if the if the contract is a Postcondition/]
[/for]																		[comment CLOSE traverse all the contracts in the DataProcessing/]
[for (c : Contract | d.contract)]											[comment OPEN traverse all the contracts in the DataProcessing/]
	[if (c.contract.type=ContractType::INVARIANT)]							[comment OPEN checks if the if the contract is a Invariant/]
		[generateCallContract(c.contract)/]
	[/if]																	[comment CLOSE checks if the if the contract is a Invariant/]
[/for]
	[if (d.outgoing<>null)]													[comment OPEN checks if the DataProcessing has an outgoing link (it's not the last)/]
[let nextDp : DataProcessing = d.outgoing.target.oclAsType(DataProcessing)] [comment OPEN assigns the next DataProcessing to a variable/]
[callContractsRecursiveTemplate(nextDp)/]			[comment Recursive call to this template to generate all the DataProcessings linked to the first/]
[/let]																		[comment OPEN assigns the next DataProcessing to a variable/]
	[/if]																	[comment CLOSE checks if the DataProcessing has an outgoing link (it's not the last)/]
[/template]

[comment]################################################################################################################################################################[/comment]

[template public generateTransformationsDataProcessing(aWorkflow : Workflow)]
[file ('transformations.py', false, 'UTF-8')]
import os
import pandas as pd
import functions.data_transformations as data_transformations
from helpers.enumerations import Belong, Operator, Operation, SpecialType, DataType, DerivedType, Closure
[comment generate the imports and the class/]
class DataProcessing:
	def generateDataProcessing(self):
		transformations=data_transformations.DataTransformations()
	[for (d : DataProcessing | aWorkflow.dataprocessing)]				[comment OPEN traverse all the DataProcessings/]
	[if (d.incoming = null and d.outgoing=null)]						[comment OPEN checks if the DataProcessing is isolated (no links)/]
#-----------------New DataProcessing-----------------
			[for (dc : DataDictionary | d.inputPort)]					[comment OPEN read all the input datasets and store them/]
		[dc.name/]=pd.read_csv('[dc.path/]')

			[/for]														[comment CLOSE read all the input datasets and store them/]
		[generateCallTransformation(d)/]
	[/if]																[comment CLOSE checks if the DataProcessing is isolated (no links)/]
	[/for]																[comment CLOSE traverse all the DataProcessings/]
	[for (d : DataProcessing | aWorkflow.dataprocessing)]				[comment OPEN traverse all the DataProcessings/]
	[if (d.incoming = null and d.outgoing<>null)]						[comment OPEN checks if the DataProcessing is the first (no input link, an output link)/]
[callTransformationsRecursiveTemplate(d)/]
	[/if]																[comment CLOSE checks if the DataProcessing is the first (no input link, an output link)/]
	[/for]																[comment CLOSE traverse all the DataProcessings/]


dp=DataProcessing()
dp.generateDataProcessing()
[/file]
[/template]


[template public callTransformationsRecursiveTemplate(d : DataProcessing)]
#-----------------New DataProcessing-----------------
[for (dc : DataDictionary | d.inputPort)]									[comment OPEN read all the input datasets and store them/]
		[dc.name/]=pd.read_csv('[dc.path/]')
[/for]																		[comment CLOSE read all the input datasets and store them/]
		[generateCallTransformation(d)/]
[if (d.outgoing<>null)]														[comment OPEN checks if the DataProcessing has an outgoing link (it's not the last)/]
	[let nextDp : DataProcessing = d.outgoing.target.oclAsType(DataProcessing)] [comment OPEN assigns the next DataProcessing to a variable/]
[callTransformationsRecursiveTemplate(nextDp)/]				[comment Recursive call to this template to generate all the DataProcessings linked to the first/]
	[/let]																	[comment OPEN assigns the next DataProcessing to a variable/]
[/if]																		[comment CLOSE checks if the DataProcessing has an outgoing link (it's not the last)/]
[/template]



[template public generateCallTransformation(dataProcessing : DataProcessing)]
[comment]The code below generates the mapping transformations[/comment]
[if (dataProcessing.parameter->notEmpty())]																[comment OPEN checks that there are parameters in the DataProcessing/]
[if (dataProcessing.parameter->first().oclIsTypeOf(Map))]												[comment OPEN checks that the first parameter is a Mapping (FixValue-FixValue)/]
[for (dd_out : DataDictionary | dataProcessing.outputPort)]									[comment OPEN traverse all the output DataDictionaries (in theory there is only 1)/]
	[for (dd_in : DataDictionary | dataProcessing.inputPort)]									[comment OPEN traverse all the input DataDictionaries (in theory there is only 1)/]
		[if dd_in.datafield->notEmpty()]																[comment OPEN checks that there is at least one DataField/]
			[for (df : DataField | dd_in.datafield)]											[comment OPEN traverse all the DataFields in the input DataDictionary (the same as in the output DataDictionary)/]
input_values_list_[dataProcessing.parameter->first().name/]=['['/][for (aParameter : Parameter | dataProcessing.parameter)  separator(', ')][if (aParameter.oclIsTypeOf(Map))][let map : Map = aParameter.oclAsType(Map)][if (df.dataType=DataType::String or df.dataType=DataType::DateTime or df.dataType=DataType::Time)]'[map.inValue/]'[else][map.inValue/][/if][/let][/if][/for][']'/]
output_values_list_[dataProcessing.parameter->first().name/]=['['/][for (aParameter : Parameter | dataProcessing.parameter)  separator(', ')][if (aParameter.oclIsTypeOf(Map))][let map : Map = aParameter.oclAsType(Map)][if (df.dataType=DataType::String or df.dataType=DataType::DateTime or df.dataType=DataType::Time)]'[map.outvalue/]'[else][map.outvalue/][/if][/let][/if][/for][']'/]
data_type_input_list_[dataProcessing.parameter->first().name/]=['['/][for (aParameter : Parameter | dataProcessing.parameter) separator(', ')][if (aParameter.oclIsTypeOf(Map))][let map : Map = aParameter.oclAsType(Map)][if (df.dataType=DataType::String)]DataType(0)[elseif (df.dataType=DataType::Time)]DataType(1)[elseif (df.dataType=DataType::Integer)]DataType(2)[elseif (df.dataType=DataType::DateTime)]DataType(3)[elseif (df.dataType=DataType::Boolean)]DataType(4)[elseif (df.dataType=DataType::Double)]DataType(5)[elseif (df.dataType=DataType::Float)]DataType(6)[else]None[/if][/let][/if][/for][']'/]
data_type_output_list_[dataProcessing.parameter->first().name/]=['['/][for (aParameter : Parameter | dataProcessing.parameter) separator(', ')][if (aParameter.oclIsTypeOf(Map))][let map : Map = aParameter.oclAsType(Map)][if (df.dataType=DataType::String)]DataType(0)[elseif (df.dataType=DataType::Time)]DataType(1)[elseif (df.dataType=DataType::Integer)]DataType(2)[elseif (df.dataType=DataType::DateTime)]DataType(3)[elseif (df.dataType=DataType::Boolean)]DataType(4)[elseif (df.dataType=DataType::Double)]DataType(5)[elseif (df.dataType=DataType::Float)]DataType(6)[else]None[/if][/let][/if][/for][']'/]


[dd_out.name/]=transformations.transform_fix_value_fix_value(data_dictionary=[dd_in.name/], input_values_list=input_values_list_[dataProcessing.parameter->first().name/],
															  output_values_list=output_values_list_[dataProcessing.parameter->first().name/],
						                                      data_type_input_list = data_type_input_list_[dataProcessing.parameter->first().name/],
						                                      data_type_output_list = data_type_output_list_[dataProcessing.parameter->first().name/], field = '[df.displayName/]')

[dd_out.name/].to_csv('[dd_out.name/].csv')
			[/for]																						[comment CLOSE traverse all the DataFields in the input DataDictionary (the same as in the output DataDictionary)/]
		[else]																							[comment OPEN checks that there are no DataField/]
input_values_list_[dataProcessing.parameter->first().name/]=['['/][for (aParameter : Parameter | dataProcessing.parameter)  separator(', ')][if (aParameter.oclIsTypeOf(Map))][let map : Map = aParameter.oclAsType(Map)]'[map.inValue/]'[/let][/if][/for][']'/]
output_values_list_[dataProcessing.parameter->first().name/]=['['/][for (aParameter : Parameter | dataProcessing.parameter)  separator(', ')][if (aParameter.oclIsTypeOf(Map))][let map : Map = aParameter.oclAsType(Map)]'[map.outvalue/]'[/let][/if][/for][']'/]

[dd_out.name/]=transformations.transform_fix_value_fix_value(data_dictionary=[dd_in.name/], input_values_list=input_values_list_[dataProcessing.parameter->first().name/],
															  output_values_list=output_values_list_[dataProcessing.parameter->first().name/],
						                                      data_type_input_list = None,
						                                      data_type_output_list = None, field = None)

[dd_out.name/].to_csv('[dd_out.name/].csv')				
		[/if]																							[comment CLOSE checks that there are DataFields or not/]
	[/for]																								[comment CLOSE traverse all the input DataDictionaries (in theory there is only 1)/]
[/for]																									[comment CLOSE traverse all the output DataDictionaries (in theory there is only 1)/]
[/if]																									[comment CLOSE checks that the first parameter is a Mapping (FixValue-FixValue)/]
[comment]The code below generates the transformations different from mapping for every field[/comment]
[if (not dataProcessing.parameter->first().oclIsTypeOf(Map))]											[comment OPEN checks that the first parameter is not a Mapping/]
[for (dd_in : DataDictionary | dataProcessing.inputPort)]
[dd_in.name/]_transformed=[dd_in.name/].copy()
[/for]
[for (p : Parameter | dataProcessing.parameter)]														[comment OPEN traverse all the parameters in the DataProcessing/]
    [if (p.oclIsKindOf(ImputeType))]																	[comment OPEN checks that the parameter is an ImputeType/]
        [let imType : ImputeType = p.oclAsType(ImputeType)]												[comment OPEN assigns the parameter to be an ImputeType/]
			[for (dd_out : DataDictionary | dataProcessing.outputPort)]									[comment OPEN traverse all the output DataDictionaries (in theory there is only 1)/]
				[for (dd_in : DataDictionary | dataProcessing.inputPort)]								[comment OPEN traverse all the input DataDictionaries (in theory there is only 1)/]
					[if dd_in.datafield->notEmpty()]													[comment OPEN checks that there is at least DataField/]
						[for (df : DataField | dd_in.datafield)]										[comment OPEN traverse all the DataFields in the input DataDictionary (the same as in the output DataDictionary)/]
missing_values_list_[p.name/]=['['/][for (mv : ValueField | df.missingValues) separator(', ')][if (df.dataType=DataType::String or df.dataType=DataType::DateTime or df.dataType=DataType::Time)]'[mv.value/]'[else][mv.value/][/if][/for][']'/]
				            [if (imType.oclIsKindOf(FixValue))]											[comment OPEN checks that the ImputeType is a FixValue/]
            	    			[let fv : FixValue = imType.oclAsType(FixValue)]						[comment OPEN assigns the ImputeType as a FixValue/]
[dd_in.name/]_transformed=transformations.transform_special_value_fix_value(data_dictionary=[dd_in.name/]_transformed,
															  special_type_input=SpecialType([if (fv.imputeValue=ImputeValue::Missing)]0[elseif (fv.imputeValue=ImputeValue::Invalid)]1[elseif (fv.imputeValue=ImputeValue::Outlier)]2[/if]), fix_value_output=[if (df.dataType=DataType::String or df.dataType=DataType::DateTime or df.dataType=DataType::Time)]'[fv.value/]'[else][fv.value/][/if],
															  missing_values=missing_values_list_[p.name/],
						                                      data_type_output = [if (df.dataType=DataType::String)]DataType(0)[elseif (df.dataType=DataType::Time)]DataType(1)[elseif (df.dataType=DataType::Integer)]DataType(2)[elseif (df.dataType=DataType::DateTime)]DataType(3)[elseif (df.dataType=DataType::Boolean)]DataType(4)[elseif (df.dataType=DataType::Double)]DataType(5)[elseif (df.dataType=DataType::Float)]DataType(6)[else]None[/if],
															  axis_param=0, field = '[df.displayName/]')
			                	[/let]																	[comment CLOSE assigns the ImputeType as a FixValue/]
			            	[/if]																		[comment CLOSE checks that the ImputeType is a FixValue/]
            				[if (imType.oclIsKindOf(DerivedValue))]										[comment OPEN checks that the ImputeType is a DerivedValue/]
                				[let dv : DerivedValue = imType.oclAsType(DerivedValue)]				[comment OPEN assigns the ImputeType as a DerivedValue/]
[dd_in.name/]_transformed=transformations.transform_special_value_derived_value(data_dictionary=[dd_in.name/]_transformed,
															  special_type_input=SpecialType([if (dv.imputeValue=ImputeValue::Missing)]0[elseif (dv.imputeValue=ImputeValue::Invalid)]1[elseif (dv.imputeValue=ImputeValue::Outlier)]2[/if]), derived_type_output=DerivedType([if (dv.type=DerivedType::MostFrequent)]0[elseif (dv.type=DerivedType::Previous)]1[elseif (dv.type=DerivedType::Next)]2[/if]),
															  missing_values=missing_values_list_[p.name/],
															  axis_param=0, field = '[df.displayName/]')
			                	[/let]																	[comment CLOSE assigns the ImputeType as a DerivedValue/]
			            	[/if]																		[comment CLOSE checks that the ImputeType is a DerivedValue/]
            				[if (imType.oclIsKindOf(NumOp))]											[comment OPEN checks that the ImputeType is a NumOp/]
                				[let nop : NumOp = imType.oclAsType(NumOp)]								[comment OPEN assigns the ImputeType as a NumOp/]
[dd_in.name/]_transformed=transformations.transform_special_value_num_op(data_dictionary=[dd_in.name/]_transformed,
															  special_type_input=SpecialType([if (nop.imputeValue=ImputeValue::Missing)]0[elseif (nop.imputeValue=ImputeValue::Invalid)]1[elseif (nop.imputeValue=ImputeValue::Outlier)]2[/if]), num_op_output=Operation([if (nop.operation=Operation::Interpolation)]0[elseif (nop.operation=Operation::Mean)]1[elseif (nop.operation=Operation::Median)]2[elseif (nop.operation=Operation::Closest)]3[/if]),
															  missing_values=missing_values_list_[p.name/],
															  axis_param=0, field = '[df.displayName/]')
			                	[/let]																	[comment CLOSE assigns the ImputeType as a NumOp/]
			            	[/if]																		[comment CLOSE checks that the ImputeType is a NumOp/]
						[/for]																			[comment CLOSE traverse all the DataFields in the input DataDictionary (the same as in the output DataDictionary)/]

[dd_out.name/]=[dd_in.name/]_transformed
[dd_out.name/].to_csv('[dd_out.name/].csv')
[comment]The code below generates the same transformation generated above but for the whole dataframe instead of a field[/comment]
					[else]																				[comment OPEN checks that there are no DataFields/]
						[if (imType.oclIsKindOf(FixValue))]												[comment OPEN checks that the ImputeType is a FixValue/]
			            	[let fv : FixValue = imType.oclAsType(FixValue)]							[comment OPEN assigns the ImputeType as a FixValue/]
[dd_out.name/]=transformations.transform_special_value_fix_value(data_dictionary=[dd_in.name/],
															  special_type_input=SpecialType([if (imType.imputeValue=ImputeValue::Missing)]0[elseif (imType.imputeValue=ImputeValue::Invalid)]1[elseif (imType.imputeValue=ImputeValue::Outlier)]2[/if]), fix_value_output='[fv.value/]', missing_values=None
						                                      data_type_output = None, axis_param=0, field = None)
			            	[/let]																		[comment CLOSE assigns the ImputeType as a FixValue/]
			        	[/if]																			[comment CLOSE checks that the ImputeType is a FixValue/]
        				[if (imType.oclIsKindOf(DerivedValue))]											[comment OPEN checks that the ImputeType is a DerivedValue/]
            				[let dv : DerivedValue = imType.oclAsType(DerivedValue)]					[comment OPEN assigns the ImputeType as a DerivedValue/]
[dd_out.name/]=transformations.transform_special_value_derived_value(data_dictionary=[dd_in.name/],
															  special_type_input=SpecialType([if (dv.imputeValue=ImputeValue::Missing)]0[elseif (dv.imputeValue=ImputeValue::Invalid)]1[elseif (dv.imputeValue=ImputeValue::Outlier)]2[/if]), derived_type_output=DerivedType([if (dv.type=DerivedType::MostFrequent)]0[elseif (dv.type=DerivedType::Previous)]1[elseif (dv.type=DerivedType::Next)]2[/if]),
															  missing_values=None, axis_param=0, field = None)
			            	[/let]																		[comment CLOSE assigns the ImputeType as a DerivedValue/]
			        	[/if]																			[comment CLOSE checks that the ImputeType is a DerivedValue/]
        				[if (imType.oclIsKindOf(NumOp))]												[comment OPEN checks that the ImputeType is a NumOp/]
                			[let nop : NumOp = imType.oclAsType(NumOp)]									[comment OPEN assigns the ImputeType as a NumOp/]
[dd_out.name/]=transformations.transform_special_value_num_op(data_dictionary=[dd_out.name/],
															  special_type_input=SpecialType([if (nop.imputeValue=ImputeValue::Missing)]0[elseif (nop.imputeValue=ImputeValue::Invalid)]1[elseif (nop.imputeValue=ImputeValue::Outlier)]2[/if]), num_op_output=Operation([if (nop.operation=Operation::Interpolation)]0[elseif (nop.operation=Operation::Mean)]1[elseif (nop.operation=Operation::Median)]2[elseif (nop.operation=Operation::Closest)]3[/if]),
															  missing_values=None, axis_param=0, field = None')
			            	[/let]																		[comment CLOSE assigns the ImputeType as a NumOp/]
			        	[/if]																			[comment CLOSE checks that the ImputeType is a NumOp/]

[dd_out.name/].to_csv('[dd_out.name/].csv')
					[/if]																				[comment CLOSE checks if there are DataFields or not/]
				[/for]																					[comment CLOSE traverse all the input DataDictionaries (in theory there is only 1)/]
			[/for]																						[comment CLOSE traverse all the output DataDictionaries (in theory there is only 1)/]
		[/let]																							[comment CLOSE assigns the parameter to be an ImputeType/]
	[/if]																								[comment CLOSE checks that the parameter is an ImputeType/]
	[if (p.oclIsKindOf(DiscretizeBin))]																	[comment OPEN checks that the parameter is an DiscretizeBin/]
		[let binner : DiscretizeBin = p.oclAsType(DiscretizeBin)]										[comment OPEN assigns the parameter to be a DiscretizeBin/]
			[for (dd_out : DataDictionary | dataProcessing.outputPort)]									[comment OPEN traverse all the output DataDictionaries (in theory there is only 1)/]
				[for (dd_in : DataDictionary | dataProcessing.inputPort)]								[comment OPEN traverse all the input DataDictionaries (in theory there is only 1)/]
					[if dd_in.datafield->notEmpty()]													[comment OPEN checks that there is at least DataField/]
						[for (df : DataField | dd_in.datafield)]										[comment OPEN traverse all the DataFields in the input DataDictionary/]
							[for (interval : Interval | binner.interval)]								[comment OPEN traverse all the intervals in the binner/]

[dd_in.name/]_transformed=transformations.transform_interval_fix_value(data_dictionary=[dd_in.name/]_transformed,
															  left_margin=[interval.leftMargin/], right_margin=[interval.rightMargin/],
															  closure_type=Closure([if (interval.clousure=ClosureType::opeOpen)]0[elseif(interval.clousure=ClosureType::openClosed)]1[elseif(interval.clousure=ClosureType::closedOpen)]2[elseif(interval.clousure=ClosureType::closedClosed)]3[/if]),
															  fix_value_output=[if (df.out.dataType=DataType::String or df.out.dataType=DataType::DateTime or df.out.dataType=DataType::Time)]'[binner.binValue/]'[else][binner.binValue/][/if],
						                                      data_type_output = [if (df.out.dataType=DataType::String)]DataType(0)[elseif (df.out.dataType=DataType::Time)]DataType(1)[elseif (df.out.dataType=DataType::Integer)]DataType(2)[elseif (df.out.dataType=DataType::DateTime)]DataType(3)[elseif (df.out.dataType=DataType::Boolean)]DataType(4)[elseif (df.out.dataType=DataType::Double)]DataType(5)[elseif (df.out.dataType=DataType::Float)]DataType(6)[else]None[/if],
															  axis_param=0, field_in = '[df.displayName/]',
															  field_out = '[df.out.displayName/]')
							[/for]																		[comment CLOSE traverse all the intervals in the binner/]
						[/for]																			[comment CLOSE traverse all the DataFields in the input DataDictionary/]
					[else]																				[comment OPEN checks that there are not DataFields/]
						[for (interval : Interval | binner.interval)]									[comment OPEN traverse all the intervals in the binner/]

[dd_in.name/]_transformed=transformations.transform_interval_fix_value(data_dictionary=[dd_in.name/]_transformed,
														  left_margin=[interval.leftMargin/], right_margin=[interval.rightMargin/],
														  closure_type=Closure([if (interval.clousure=ClosureType::opeOpen)]0[elseif(interval.clousure=ClosureType::openClosed)]1[elseif(interval.clousure=ClosureType::closedOpen)]2[elseif(interval.clousure=ClosureType::closedClosed)]3[/if]),
														  fix_value_output='[binner.binValue/]', data_type_output = None, axis_param=0, field_in = None, field_out = None)
						[/for]																			[comment CLOSE traverse all the intervals in the binner/]
					[/if]																				[comment CLOSE checks if there are DataFields/]
[dd_out.name/]=[dd_in.name/]_transformed
[dd_out.name/].to_csv('[dd_out.name/].csv')
				[/for]																					[comment CLOSE traverse all the intervals in the binner/]
			[/for]																						[comment CLOSE traverse all the DataFields in the input DataDictionary/]
		[/let]																							[comment OPEN assigns the parameter to be an DiscretizeBin/]
	[/if]																								[comment CLOSE checks that the parameter is an DiscretizeBin/]
	[if (p.oclIsKindOf(DerivedField))]																	[comment OPEN checks that the parameter is a DerivedField/]
		[let derf : DerivedField = p.oclAsType(DerivedField)]											[comment OPEN assigns the parameter to be a DerivedField/]
[for (dd_in : DataDictionary | dataProcessing.inputPort)]												[comment OPEN traverse al the input DataDictionaries/]
[dd_in.name/]_transformed=transformations.transform_derived_field(data_dictionary=[dd_in.name/]_transformed,
															  data_type_output = [if (derf.der_dataType=DataType::String)]DataType(0)[elseif (derf.der_dataType=DataType::Time)]DataType(1)[elseif (derf.der_dataType=DataType::Integer)]DataType(2)[elseif (derf.der_dataType=DataType::DateTime)]DataType(3)[elseif (derf.der_dataType=DataType::Boolean)]DataType(4)[elseif (derf.der_dataType=DataType::Double)]DataType(5)[elseif (derf.der_dataType=DataType::Float)]DataType(6)[else]None[/if],
															  field_in = '[derf.der_dataField._in.displayName/]', field_out = '[derf.der_name/]')
[/for]																									[comment CLOSE traverse al the input DataDictionaries/]
		[/let]																							[comment CLOSE assigns the parameter to be a DerivedField/]
	[/if]																								[comment CLOSE checks that the parameter is a DerivedField/]
[/for]																									[comment CLOSE traverse all the parameters in the DataProcessing/]
[/if]																									[comment CLOSE checks that the first parameter is not a Mapping/]
[/if]																									[comment CLOSE checks that there are parameters in the DataProcessing/]
[/template]




